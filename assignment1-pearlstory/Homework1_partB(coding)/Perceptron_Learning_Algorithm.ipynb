{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Learning Algorithm\n",
    "\n",
    "The perceptron is a simple supervised machine learning algorithm and one of the earliest neural network architectures. It was introduced by Rosenblatt in the late 1950s. A perceptron represents a binary linear classifier that maps a set of training examples (of $d$ dimensional input vectors) onto binary output values using a $d-1$ dimensional hyperplane. But Today, we will implement **Multi-Classes Perceptron Learning Algorithm** \n",
    "**Given:**\n",
    "* dataset $\\{(x^i, y^i)\\}$, $i \\in (1, M)$\n",
    "* $x^i$ is $d$ dimension vector, $x^i = (x^i_1, \\dots x^i_d)$\n",
    "* $y^i$ is multi-class target varible $y^i \\in \\{0,1,2\\}$\n",
    "\n",
    "A perceptron is trained using gradient descent. The training algorithm has different steps. In the beginning (step 0) the model parameters are initialized. The other steps (see below) are repeated for a specified number of training iterations or until the parameters have converged.\n",
    "\n",
    "**Step0:** Initial the weight vector and bias with zeros     \n",
    "**Step1:** Compute the linear combination of the input features and weight. $y^i_{pred} = argmax_k W_k*x^i + b$    \n",
    "**Step2:** Compute the gradients for parameters $W_k$, $b$. **Derive the parameter update equation Here(5 points)**   \n",
    "\n",
    "##################################     \n",
    "TODO: Derive you answer here\n",
    "#################################\n",
    "\n",
    "$b=b-\\alpha\\dfrac{1}{M}\\Big[\\sum\\limits_{i=1}^M(y^i=k \\&\\& y^i_{pred}\\neq y^i)\\cdot1+\\sum\\limits_{j=1}^M(y^j\\neq k\\&\\&y^i_{pred}=k)\\cdot1\\Big] $  \n",
    "\n",
    "$W_k=W_k-\\alpha\\dfrac{1}{M}\\Big[\\sum\\limits_{i=1}^M(y^i=k \\&\\& y^i_{pred}\\neq y^i)x^i+\n",
    "\\sum\\limits_{j=1}^M(y^j\\neq k\\&\\&y^i_{pred}=k)x^j\\Big]$   \n",
    "\n",
    "for all $x^i(i \\in (1, M))$ where $k={0,1,2}$ and $\\alpha$ is learning rate                            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "X_Shape: (150, 4)\n",
      "y_Shape: (150,)\n",
      "Label Space: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "print(type(X))\n",
    "y = iris.target\n",
    "y = np.array(y)\n",
    "print('X_Shape:', X.shape)\n",
    "print('y_Shape:', y.shape)\n",
    "print('Label Space:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_Shape: (105, 4)\n",
      "X_test_Shape: (45, 4)\n",
      "y_train_Shape: (105,)\n",
      "y_test_Shape: (45,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "## split the training set and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "print('X_train_Shape:', X_train.shape)\n",
    "print('X_test_Shape:',  X_test.shape)\n",
    "print('y_train_Shape:', y_train.shape)\n",
    "print('y_test_Shape:',  y_test.shape)\n",
    "\n",
    "print(type(y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiClsPLA(object):\n",
    "    \n",
    "    ## We recommend to absorb the bias into weight.  W = [w, b]\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, lr, num_epoch, weight_dimension, num_cls):\n",
    "        super(MultiClsPLA, self).__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.weight = self.initial_weight(weight_dimension, num_cls)\n",
    "        self.sample_mean = np.mean(self.X_train, 0)\n",
    "        self.sample_std = np.std(self.X_train, 0)\n",
    "        self.num_epoch = num_epoch\n",
    "        self.lr = lr\n",
    "        self.total_acc_train = []\n",
    "        self.total_acc_tst = []\n",
    "          \n",
    "    def initial_weight(self, weight_dimension, num_cls):\n",
    "        weight = None\n",
    "        #########################################\n",
    "        ##  ToDO: Initialize the weight with   ##\n",
    "        ##  small std and zero mean gaussian   ##\n",
    "        #########################################\n",
    "        # choose Gaussian distribution with (0,1e-4)\n",
    "        weight = 1e-2*np.random.randn(weight_dimension[0],weight_dimension[1]) + 0\n",
    "        return weight\n",
    "        \n",
    "    def data_preprocessing(self, data):\n",
    "        #####################################\n",
    "        ##  ToDO: Normalize the data        ##\n",
    "        #####################################\n",
    "        norm_data = (data-self.sample_mean)/self.sample_std\n",
    "        return norm_data\n",
    "    \n",
    "    def train_step(self, X_train, y_train, shuffle_idx):\n",
    "        np.random.shuffle(shuffle_idx)\n",
    "        X_train = X_train[shuffle_idx]\n",
    "        y_train = y_train[shuffle_idx]\n",
    "        train_acc = None\n",
    "        ##############################################\n",
    "        ## TODO: to implement the training process  ##\n",
    "        ## and update the weights                   ##\n",
    "        ##############################################\n",
    "        # training process\n",
    "        dW = np.zeros(self.weight.shape)\n",
    "                \n",
    "        num_train = X_train.shape[0]\n",
    "        num_class = self.weight.shape[1]\n",
    "        for i in range(num_train):\n",
    "            \n",
    "            score = X_train[i].dot(self.weight)\n",
    "            correct_class_score = score[y_train[i]]\n",
    "            for j in range(num_class):\n",
    "                if j == y_train[i]:\n",
    "                    continue\n",
    "                # add penalty on wrong labels for this datapoint and for other labels\n",
    "                if score[j]>correct_class_score:\n",
    "                    dW[:, j] += X_train[i]\n",
    "                    dW[:, y_train[i]] -= X_train[i]\n",
    "                \n",
    "        \n",
    "        # update weight  \n",
    "        dW /= num_train\n",
    "        self.weight -= self.lr*dW             \n",
    "        scores = X_train.dot(self.weight)\n",
    "        # predict the training label\n",
    "        y_train_pre = np.argmax(scores, axis = 1)\n",
    "        train_acc = np.mean(y_train_pre == y_train)\n",
    "        \n",
    "        \n",
    "        return train_acc\n",
    "        \n",
    "    def test_step(self, X_test, y_test):\n",
    "    \n",
    "        \n",
    "        \n",
    "        num_sample = X_test.shape[0]\n",
    "        test_acc = None\n",
    "        \n",
    "        #########################################\n",
    "        ##  ToDO: Evaluate the test set and    ##\n",
    "        ##  return the test acc                ##\n",
    "        #########################################\n",
    "        \n",
    "        y_test_pre = np.argmax(X_test.dot(self.weight), axis = 1)\n",
    "        test_acc = np.mean(y_test_pre == y_test)\n",
    "        return test_acc\n",
    "        \n",
    "    def train(self):\n",
    "           \n",
    "        self.X_train = self.data_preprocessing(data=self.X_train)\n",
    "        self.X_test = self.data_preprocessing(data=self.X_test)\n",
    "        num_sample = self.X_train.shape[0]\n",
    "        \n",
    "        ######################################################\n",
    "        ### TODO: In order to absorb the bias into weights ###\n",
    "        ###  we need to modify the input data.             ###\n",
    "        ###  So You need to transform the input data       ###\n",
    "        ######################################################\n",
    "        # add bias so that only W=[W,b] is considered\n",
    "        self.X_train = np.hstack([self.X_train, np.ones((self.X_train.shape[0], 1))])\n",
    "        self.X_test = np.hstack([self.X_test, np.ones((self.X_test.shape[0], 1))])\n",
    "        \n",
    "        shuffle_index = np.array(range(0, num_sample))\n",
    "        for epoch in range(self.num_epoch):\n",
    "            training_acc = self.train_step(X_train=self.X_train, y_train=self.y_train, shuffle_idx=shuffle_index)\n",
    "            tst_acc = self.test_step(X_test=self.X_test,  y_test=self.y_test)\n",
    "            self.total_acc_train.append(training_acc)\n",
    "            self.total_acc_tst.append(tst_acc)\n",
    "            #print('epoch:', epoch, 'traing_acc:%.3f'%training_acc, 'tst_acc:%.3f'%tst_acc)\n",
    "    \n",
    "    def vis_acc_curve(self):\n",
    "        train_acc = np.array(self.total_acc_train)\n",
    "        tst_acc = np.array(self.total_acc_tst)\n",
    "        plt.plot(train_acc)\n",
    "        plt.plot(tst_acc)\n",
    "        plt.legend(['train_acc', 'tst_acc'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niBQhhbuISBFSuIuIFKH/DwAwlJRtr2rqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e6d98881d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "#######################################################\n",
    "### TODO: \n",
    "### 1. You need to import the model and pass some parameters. \n",
    "### 2. Then training the model with some epoches.\n",
    "### 3. Visualize the training acc and test acc verus epoches\n",
    "\n",
    "#from Perceptron_Learning_Algorithm import MultiClsPLA\n",
    "\n",
    "lr = 1e-3\n",
    "num_epoch=4000\n",
    "num_cls = len(np.unique(y))\n",
    "weight_dim0 = X_train.shape[1]+1\n",
    "weight_dimension = (weight_dim0, num_cls)\n",
    "MPLA = MultiClsPLA(X_train, y_train, X_test, y_test, lr, num_epoch, weight_dimension, num_cls)\n",
    "\n",
    "MPLA.train()\n",
    "\n",
    "MPLA.vis_acc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
